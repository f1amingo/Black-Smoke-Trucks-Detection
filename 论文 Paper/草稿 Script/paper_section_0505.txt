深度学习框架为我们封装了深度学习中的常用操作，可以让我们不需要自己写CUDA就能使用GPU，或者是自动帮我们求解复杂函数的梯度，大大提升开发的效率。

- TensorFlow
stars 126,816
由Google开源，以及开发维护，强大的社区支持。
拥有强大的可视化组件TensorBoard，能对网络结构以及训练过程进行可视化。
文档丰富却混乱，教程缺乏明显的条理和层次，新手很难找到一个真正循序渐进的入门教程。

- Keras
stars 40,840
一个非常高层的库，可以工作在Theano、TensorFlow、CNTK等后端之上，操作简单、上手容易、文档资料丰富、环境配置容易，简化了神经网络构建代码编写的难度。。
Keras为支持快速实验而生，能够快速验证你的idea。
强调极简主义——你只需几行代码就能构建一个神经网络。
过度封装导致灵活性丧失，Keras速度较慢，容易让人觉得只是在调用接口，很难学习到深度学习的内容。

- Caffe 27,982
Caffe是一个清晰而高效的深度学习框架，也是一个被广泛使用的开源深度学习框架。
上手容易，网络结构都是以配置文件形式定义，不需要用代码设计网络。
训练速度快，组件模块化，可以方便的拓展到新的模型和学习任务上。
Caffe最开始设计时的目标只针对于图像，没有考虑文本、语音或者时间序列的数据，因此Caffe对卷积神经网络的支持非常好，但是对于时间序列RNN，LSTM等支持的不是特别充分。
性能优异，但文档不够完善

- PyTorch 27,662
2017年1月，由Facebook人工智能研究院（FAIR）团队在GitHub上开源。
Torch的编程语言是Lua，PyTorch重新利用python设计实现了Torch。
PyTorch的设计追求最少的封装，灵活快速，简单易用
除了官方文档以外，只有有限的参考资源


- MXNet 16,809
起源于开源社区的项目，得到Amazon的支持推广，广泛使用于AWS，2017年1月进入Apache基金会，成为Apache孵化器项目。
借鉴了之前各个开源框架的长处，设计更加合理。支持分布式，对多主机、多GPU支持非常方便。
资源利用率高，对深度学习计算做了专门优化，计算效率高，节省GPU显存，在同等情况下可使用更大的batch size。
