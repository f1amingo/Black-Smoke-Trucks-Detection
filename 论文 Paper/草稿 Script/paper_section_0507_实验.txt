4.2	深度神经网络构建与训练
本文实验环境如下：
硬件环境：
	CPU：Intel(R) Xeon(R) CPU E5-2660 v3 2.60GHz（2核）
	GPU：Nvida TITAN X 显存12G
	内存：10G
软件环境：
	操作系统：Ubuntu 16.04
	CUDA版本：10.0
	cuDNN版本：7.4
	Python：3.76
	MXNet版本：mxnet-cu100 1.4.0.post0
	gluoncv版本：gluoncv 0.4.0.post0

4.2.1	初次训练与使用微调
在本轮实验中，我们从处理后的数据集中随机抽出500图片作为测试数据集，剩下的作为训练集。为了缩短训练时间，尽快得到结果，初次训练选择较小的网络模型MobileNet V1作为我们的特征提取网络。
初次训练不使用任何在其他公开图片数据集上已经训练好的网络模型参数，将网络输入图片大小设置为512*512，使用小批量随机梯度下降算法，batch size为32，学习率为0.01。在训练了【XXX】个epoch后，模型在训练集上的准确度达到了【XXX】，下图为模型训练过程中loss变化曲线，以及在测试集上准确度的变化曲线。
【loss acc图】
【遇到困难】可以发现在训练了一定epoch之后，模型在测试集上的准确度，不再继续上升。
为了解决以上问题，我们使用迁移学习（transfer learning）的方法，大大缩短了训练时间，并且获得了更高的准确度。
在实际应用深度学习时，我们常常会碰到，因为数据量有限而导致最终训练得到的模型精度达不到实用要求的问题，或者是因为数据集规模太小，涵盖的场景不够丰富而导致模型在训练集上过拟合。针对以上问题，一个显而易见的解决方法是收集更多的数据。然而，收集数据、标记数据会花费大量的时间成本和金钱。比如著名的ImageNet数据集的收集就花费了研究人员数百万美元的研究经费。
另一种解决办法是应用迁移学习，将模型从其他源数据集学习到的知识迁移到目标数据集上。我们之所以可以这样做，是因为在源数据集上训练的模型可以提取出一些通用的图像特征，从而能帮助识别边缘、纹理、形状和物体组成等，这些类似的特征对于识别我们感兴趣的物体可能也同样有效。
应用迁移学习的一种常用技术手段是微调(fine tuning)，微调一般由以下一些步骤组成：
1.在源数据集（如ImageNet数据集）上预训练一个神经网络模型，即源模型。
2.创建一个新的神经网络模型，即目标模型。它复制了源模型上除了输出层外的所有模型设计及其参数。我们假设这些模型参数包含了源数据集上学习到的知识，且这些知识同样适用于目标数据集。我们还假设源模型的输出层跟源数据集的标签紧密相关，因此在目标模型中不予采用。
3.为目标模型添加一个输出大小为目标数据集类别个数的输出层，并随机初始化该层的模型参数。
4.在目标数据集（如椅子数据集）上训练目标模型。我们将从头训练输出层，而其余层的参数都是基于源模型的参数微调得到的。
【微调示意图】
接下来，我们将使用在PASCAL VOC数据集上预训练的MobileNet V1作为源模型，我们将源模型的输出层进行修改，将其输出个数修改为1，我们仅关注黑烟尾气这一个对象，保留其他层的所有参数。模型输入图片大小仍为512*512，使用小批量随机梯度下降算法，batch size为32，学习率调整为0.01，开始训练模型。训练结果如下，在迭代了【XXX】个epoch后，我们已经达到了【XXX】的识别准确度，训练效率远高于从头开始训练模型。