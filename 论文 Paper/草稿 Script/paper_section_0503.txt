- CNN：
单就计算机视觉而言，CNN可以被用于物体检测、物体分割、风格转换等，但实际上CNN真正能做的，只是起到一个特征提取器的作用，以上的应用也都是建立在CNN对图像进行特征提取的基础上进行的。

- 卷积层Conv（Convolutional layer）
普通神经网络（多层感知机）将输入层与隐含层进行全连接，从计算的角度看，这种方式对于更大的图像输入将需要更多的输入单元，随之而来的还有更加大量的网络参数，28*28的图像需要784的输入单元，而更大的图像96*96将需要9216个输入单元，这会消耗更多的内存与计算资源。另一方面，普通神经网络将图像展开为一个个像素然后输入进网络，这样的方式会对物体在图像中的位置产生较大的依赖性，并且无法表征图像局部空间的特征。
我们以二维卷积为例简单介绍卷积层，在二维卷积层中，一个二维输入数组和一个二维核（kernal）数组通过卷积运算输出一个二维数组。如图5.1所示，输入是一个高和宽均为3的二维数组。我们将该数组的形状记为 3×3 或（3，3）。核数组的高和宽分别为2。该数组在卷积计算中又称卷积核或过滤器（filter）。卷积核窗口（又称卷积窗口）的形状取决于卷积核的高和宽，即 2×2 。图5.1中的阴影部分为第一个输出元素及其计算所使用的输入和核数组元素： 0×0+1×1+3×2+4×3=19 。
在二维卷积运算中，卷积窗口从输入数组的最左上方开始，按从左往右、从上往下的顺序，依次在输入数组上滑动。当卷积窗口滑动到某一位置时，窗口中的输入子数组与核数组按元素相乘并求和，得到输出数组中相应位置的元素。
通过上面的介绍我们可以发现，卷积层可通过重复使用卷积核有效地表征局部空间，比如检测图像中物体的边缘，即找到像素变化的位置。
二维卷积层输出的二维数组可以看作是输入在空间维度（宽和高）上某一级的表征，也叫特征图（feature map）。影响元素 x 的前向计算的所有可能输入区域（可能大于输入的实际尺寸）叫做 x 的感受野（receptive field）。以图5.1为例，输入中阴影部分的四个元素是输出中阴影部分元素的感受野。我们将图5.1中形状为 2×2 的输出记为 Y ，并考虑一个更深的卷积神经网络：将 Y 与另一个形状为 2×2 的核数组做互相关运算，输出单个元素 z 。那么， z 在 Y 上的感受野包括 Y 的全部四个元素，在输入上的感受野包括其中全部9个元素。可见，我们可以通过更深的卷积神经网络使特征图中单个元素的感受野变得更加广阔，从而捕捉输入上更大尺寸的特征。
填充可以增加输出的高和宽。这常用来使输出与输入具有相同的高和宽。
步幅可以减小输出的高和宽，例如输出的高和宽仅为输入的高和宽的 1/n （ n 为大于1的整数）。


- 线性整流层Relu（Rectified Linear Units layer, ReLU layer）
- 池化层Pool（Pooling layer）
- 全连接层FC（ Fully-Connected layer）